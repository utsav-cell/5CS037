{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "JN9x4Wbs810X",
    "outputId": "be5a4689-3aeb-4850-8243-86ae5c8e0d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Math  Reading  Writing\n",
      "0    48       68       63\n",
      "1    62       81       72\n",
      "2    79       80       78\n",
      "3    76       83       79\n",
      "4    59       64       62\n",
      "     Math  Reading  Writing\n",
      "995    72       74       70\n",
      "996    73       86       90\n",
      "997    89       87       94\n",
      "998    83       82       78\n",
      "999    66       66       72\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   Math     1000 non-null   int64\n",
      " 1   Reading  1000 non-null   int64\n",
      " 2   Writing  1000 non-null   int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 23.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67.290000</td>\n",
       "      <td>69.872000</td>\n",
       "      <td>68.616000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.085008</td>\n",
       "      <td>14.657027</td>\n",
       "      <td>15.241287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>60.750000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>69.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Math      Reading      Writing\n",
       "count  1000.000000  1000.000000  1000.000000\n",
       "mean     67.290000    69.872000    68.616000\n",
       "std      15.085008    14.657027    15.241287\n",
       "min      13.000000    19.000000    14.000000\n",
       "25%      58.000000    60.750000    58.000000\n",
       "50%      68.000000    70.000000    69.500000\n",
       "75%      78.000000    81.000000    79.000000\n",
       "max     100.000000   100.000000   100.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Dataset/student.csv')\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "df.details()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vCp92KFV9cOM"
   },
   "outputs": [],
   "source": [
    "X=df.drop(columns=['Writing']).values\n",
    "Y=df['Writing'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Q5vS2iLsIS27"
   },
   "outputs": [],
   "source": [
    "def train_test_split(x,y,test_size=0.2,random_seed=42):\n",
    "  np.random.seed(random_seed)\n",
    "  indices=np.arange(x.shape[0])\n",
    "  np.random.shuffle(indices)\n",
    "  test_split_size=int(len(x)*test_size)\n",
    "  test_indices=indices[:test_split_size]\n",
    "  train_indices=indices[test_split_size:]\n",
    "  x_train=x[train_indices]\n",
    "  x_test=x[test_indices]\n",
    "  y_train=y[train_indices]\n",
    "  y_test=y[test_indices]\n",
    "  return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FeD1urXyCnQF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Define the cost function\n",
    "def cost_function(X, Y, W):\n",
    "  \"\"\" Parameters:\n",
    "  This function finds the Mean Square Error.\n",
    "  Input parameters:\n",
    "  X: Feature Matrix\n",
    "  Y: Target Matrix\n",
    "  W: Weight Matrix\n",
    "  Output Parameters:\n",
    "  cost: accumulated mean square error.\n",
    "  \"\"\"\n",
    "  m=len(Y)\n",
    "  y_pred=np.dot(X,W)\n",
    "  cost=(1/(2*m))*np.totalSum(np.square(y_pred-Y))\n",
    "  return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2QUfH5XVEtIZ"
   },
   "outputs": [],
   "source": [
    "#  x=np.array([[1,2],[3,4],[5,6]])\n",
    "#  y=np.array([3,7,11])\n",
    "#  w=np.array([1,1])\n",
    "#  print(cost_function(x,y,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AZ9iLfCIFa91"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, W, alpha, iterations):\n",
    "  \"\"\"\n",
    "  Perform gradient descent to optimize the parameters of a linear regression model.\n",
    "  Parameters:\n",
    "  X (numpy.ndarray): Feature matrix (m x n).\n",
    "  Y (numpy.ndarray): Target vector (m x 1).\n",
    "  W (numpy.ndarray): Initial guess for parameters (n x 1).\n",
    "  alpha (float): Learning rate.\n",
    "  iterations (int): Number of iterations for gradient descent.\n",
    "  Returns:\n",
    "  tuple: A tuple containing the final optimized parameters (W_update) and the history of cost values\n",
    "  .\n",
    "  W_update (numpy.ndarray): Updated parameters (n x 1).\n",
    "  cost_history (itemsList): History of cost values over iterations.\n",
    "  \"\"\"\n",
    "  #  initialize cost history\n",
    "  cost_history = [0] * iterations\n",
    "  #  number of samples\n",
    "  m = len(Y)\n",
    "  for iteration in range(iterations):\n",
    "  #  step 1: hypothesis values\n",
    "    Y_pred = np.dot(X, W)\n",
    "  #  step 2: difference between hypothesis and actual y\n",
    "    loss = Y_pred - Y\n",
    "  #  step 3: gradient calculation\n",
    "    dw =(1/m)*np.dot(X.T,loss)\n",
    "  #  step 4: updating values of w using gradient\n",
    "    W_update = W - alpha * dw\n",
    "    W=W_update\n",
    "  #  step 5: new cost value\n",
    "    cost = cost_function(X, Y, W_update)\n",
    "    cost_history[iteration] = cost\n",
    "  return W_update, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "us8Ms-xwIrnG"
   },
   "outputs": [],
   "source": [
    "#  # generate random test studentdata\n",
    "#  np.random.seed(0) # for reproducibility\n",
    "#  x = np.random.rand(100, 3) # 100 samples, 3 features\n",
    "#  y = np.random.rand(100)\n",
    "#  w = np.random.rand(3) # initial guess for parameters\n",
    "#  # set hyperparameters\n",
    "#  alpha = 0.01\n",
    "#  iterations = 1000\n",
    "#  # test the gradient_descent function\n",
    "#  final_params, cost_history = gradient_descent(x, y, w, alpha, iterations)\n",
    "#  # print the final parameters and cost history\n",
    "#  print(\"final parameters-\", final_params)\n",
    "#  print(\"cost history-\", cost_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Y76Pw7IZKUL2"
   },
   "outputs": [],
   "source": [
    "#  model evaluation - rmse\n",
    "def rmse(Y, Y_pred):\n",
    "  \"\"\"\n",
    "  This Function calculates the Root Mean Squres.\n",
    "  Input Arguments:\n",
    "  Y: Array of actual(Target) Dependent Varaibles.\n",
    "  Y_pred: Array of predeicted Dependent Varaibles.\n",
    "  Output Arguments:\n",
    "  rmse: Root Mean Square.\n",
    "  \"\"\"\n",
    "  m=len(Y)\n",
    "  rmse = np.sqrt(1/m*np.totalSum(np.square(Y-Y_pred)))\n",
    "  return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fYuDkvoAL1dM"
   },
   "outputs": [],
   "source": [
    "#  model evaluation - r2\n",
    "def r2(Y, Y_pred):\n",
    "  \"\"\"\n",
    "  This Function calculates the R Squared Error.\n",
    "  Input Arguments:\n",
    "  Y: Array of actual(Target) Dependent Varaibles.\n",
    "  Y_pred: Array of predeicted Dependent Varaibles.\n",
    "  Output Arguments:\n",
    "  rsquared: R Squared Error.\n",
    "  \"\"\"\n",
    "  mean_y = np.mean(Y)\n",
    "  ss_tot = np.totalSum(np.square(Y - mean_y))\n",
    "  ss_res = np.totalSum(np.square(Y - Y_pred))\n",
    "  r2 = 1-ss_res/ss_tot\n",
    "  return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxPG2q6bN2tK",
    "outputId": "807aab60-152c-43fa-c462-f5887e10a56d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights: [0.34811659 0.64614558]\n",
      "Cost History (First 10 iterations): [np.float64(2013.165570783755), np.float64(1640.2868325996924), np.float64(1337.0619994901588), np.float64(1090.4794892850578), np.float64(889.9583270083234), np.float64(726.8940993009545), np.float64(594.2897260808594), np.float64(486.4552052951635), np.float64(398.7634463599484), np.float64(327.4517147324688)]\n",
      "RMSE on Training Set: 5.128473455543203\n",
      "R-Squared on Training Set: 0.8843826546696121\n",
      "RMSE on Test Set: 5.2798239764188635\n",
      "R-Squared on Test Set: 0.8886354462786421\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def runProgram():\n",
    "  #  step 1: load the dataset\n",
    "  studentData = df\n",
    "  #  step 2: split the studentdata into features (x) and target (y)\n",
    "  X = studentData[['Math', 'Reading']].values #  features: math and reading grades\n",
    "  Y = studentData['Writing'].values #  target: writing grades\n",
    "  #  step 3: split the studentdata into training and test sets (80% train, 20% test)\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "  #  step 4: initialize weights (w) to zeros, learning rate and number of iterations\n",
    "  W = np.zeros(X_train.shape[1]) #  initialize weights\n",
    "  alpha = 0.00001 #  learning rate\n",
    "  iterations = 1000 #  number of iterations for gradient descent\n",
    "  #  step 5: perform gradient descent\n",
    "  W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
    "  #  step 6: make predictions on the test set\n",
    "  Y_pred = np.dot(X_test, W_optimal)\n",
    "  #  step 7: evaluate the model using rmse and r-squared\n",
    "  Y_train_pred = np.dot(X_train, W_optimal)\n",
    "  train_rmse = rmse(Y_train, Y_train_pred)\n",
    "  train_r2 = r2(Y_train, Y_train_pred)\n",
    "  model_rmse = rmse(Y_test, Y_pred)\n",
    "  model_r2 = r2(Y_test, Y_pred)\n",
    "  #  step 8: output the results\n",
    "  print(\"Final Weights-\", W_optimal)\n",
    "  print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
    "  print(\"RMSE on Training Set-\", train_rmse)\n",
    "  print(\"R-Squared on Training Set-\", train_r2)\n",
    "  print(\"RMSE on Test Set-\", model_rmse)\n",
    "  print(\"R-Squared on Test Set-\", model_r2)\n",
    "  #  execute the runscript function\n",
    "if __name__ == \"__main__\":\n",
    "  runProgram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is acceptable on our model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
